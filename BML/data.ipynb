{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning on Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "\n",
    "#there are a bunch of sun-libraries that will also be imported over here instead\n",
    "#of being imported randomly throughout the cooding experience\n",
    "import pandas as pd # type: ignore\n",
    "import numpy as np # type: ignore\n",
    "import seaborn as sns # type: ignore\n",
    "from matplotlib import pyplot as plt # type: ignore \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from ipywidgets import interact\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from sklearn import linear_model\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('IRIS.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing basic functions on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Sepal.Length</th>\n",
       "      <th>Sepal.Width</th>\n",
       "      <th>Petal.Length</th>\n",
       "      <th>Petal.Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43.445368</td>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>38.250000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75.500000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>112.750000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Sepal.Length  Sepal.Width  Petal.Length  Petal.Width\n",
       "count  150.000000    150.000000   150.000000    150.000000   150.000000\n",
       "mean    75.500000      5.843333     3.057333      3.758000     1.199333\n",
       "std     43.445368      0.828066     0.435866      1.765298     0.762238\n",
       "min      1.000000      4.300000     2.000000      1.000000     0.100000\n",
       "25%     38.250000      5.100000     2.800000      1.600000     0.300000\n",
       "50%     75.500000      5.800000     3.000000      4.350000     1.300000\n",
       "75%    112.750000      6.400000     3.300000      5.100000     1.800000\n",
       "max    150.000000      7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   ID            150 non-null    int64  \n",
      " 1   Sepal.Length  150 non-null    float64\n",
      " 2   Sepal.Width   150 non-null    float64\n",
      " 3   Petal.Length  150 non-null    float64\n",
      " 4   Petal.Width   150 non-null    float64\n",
      " 5   Species       150 non-null    object \n",
      "dtypes: float64(4), int64(1), object(1)\n",
      "memory usage: 7.2+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "900"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(150, 6)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Species\n",
       "setosa        50\n",
       "versicolor    50\n",
       "virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Sepal.Length    0\n",
       "Sepal.Width     0\n",
       "Petal.Length    0\n",
       "Petal.Width     0\n",
       "Species         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ID              0\n",
       "Sepal.Length    0\n",
       "Sepal.Width     0\n",
       "Petal.Length    0\n",
       "Petal.Width     0\n",
       "Species         0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(data.describe())\n",
    "#gives basic understanding of the dataset\n",
    "\n",
    "display(data.info())\n",
    "#NOTE: there exists 2 columns\n",
    "#1) ID column that needs to be dropped because of its increasing numeric value\n",
    "#2) Species column that contains object which should be label encoded\n",
    "\n",
    "display(data.size)\n",
    "#displays the total amount entries in every column included.\n",
    "\n",
    "display(data.shape)\n",
    "#tells us the division of rows and columns of the table\n",
    "#i.e. 6 features with 150 rows of entries\n",
    "\n",
    "display(data[\"Species\"].value_counts())\n",
    "#displays all the values on different species\n",
    "\n",
    "display(data.isna().sum())\n",
    "#checks the total number of NaN values\n",
    "#consists 0 therefore no cleaning required\n",
    "\n",
    "display(data.isnull().sum())\n",
    "#checks the total number of NULL values\n",
    "#consists 0 therefore no cleaning required\n",
    "\n",
    "display(data.duplicated().sum())\n",
    "#checks for number of duplicates in the dataset\n",
    "\n",
    "display(data.drop_duplicates(inplace=True))\n",
    "#removes that duplicate from the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing Unnecessary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['ID']  # These columns have no variance\n",
    "data = data.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outliers Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Removed 4 outliers (2.67% of data)'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def remove_outliers(data):\n",
    "    df_clean = data.copy()\n",
    "    initial_rows = len(df_clean)\n",
    "    \n",
    "    for col in df_clean.select_dtypes(exclude=['object']).columns:\n",
    "        Q1 = df_clean[col].quantile(0.25)\n",
    "        Q3 = df_clean[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        df_clean = df_clean[(df_clean[col] >= Q1 - 1.5 * IQR) & \n",
    "                           (df_clean[col] <= Q3 + 1.5 * IQR)]\n",
    "    \n",
    "    removed = initial_rows - len(df_clean)\n",
    "    display(f\"Removed {removed} outliers ({removed/initial_rows:.2%} of data)\")\n",
    "    return df_clean\n",
    "data=remove_outliers(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Sepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric Features: ['Sepal.Length', 'Sepal.Width', 'Petal.Length', 'Petal.Width']\n",
      "Categorical Features: ['Species']\n"
     ]
    }
   ],
   "source": [
    "numeric_features = data.select_dtypes(exclude=['object']).columns\n",
    "categorical_features = data.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\nNumeric Features:\", list(numeric_features))\n",
    "print(\"Categorical Features:\", list(categorical_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data=data.select_dtypes(exclude=['object'])\n",
    "categorical_feature=data.select_dtypes(include=['object'])\n",
    "\n",
    "encoder=LabelEncoder()\n",
    "for col in categorical_feature.columns:\n",
    "    data[col]=encoder.fit_transform(categorical_feature[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def scaled_data(data):\n",
    "    data_copy = data.copy()\n",
    "    scaler = StandardScaler()\n",
    "    data_copy[numeric_features] = scaler.fit_transform(data_copy[numeric_features]) \n",
    "    return data_copy\n",
    "data_scaled = scaled_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Diagrams/Logistic Regression.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389bff850b554e059c3e798db6bd8574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=6.0, description='Sl', max=7.9, min=4.3), FloatSlider(value=3.0, descr…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.Petal_Width(Sl, Sw, Pl)>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Residual sum of squares: 0.04\n"
     ]
    }
   ],
   "source": [
    "#importing data\n",
    "X=data[['Sepal.Length','Sepal.Width','Petal.Length']].values\n",
    "Y=data[['Petal.Width']]\n",
    "\n",
    "#choosing min, max of each column\n",
    "min_sl, max_sl = X[:, 0].min(), X[:, 0].max()\n",
    "min_sw, max_sw = X[:, 1].min(), X[:, 1].max()\n",
    "min_pl, max_pl = X[:, 2].min(), X[:, 2].max()\n",
    "\n",
    "#model defining and fitting\n",
    "model=LinearRegression()\n",
    "model.fit(X,Y)\n",
    "\n",
    "#function defination for input and display of petal width\n",
    "def Petal_Width(Sl, Sw, Pl):\n",
    "    prediction = model.predict([[Sl, Sw, Pl]])\n",
    "    if(prediction<0):\n",
    "        print(\"Vaues give Negative Value. Try a realistic Value\")\n",
    "    else:\n",
    "        print(f'A flower with {Sl} Sepal Length, {Sw} Sepal Width, {Pl} Petal Length will have Petal Width: {float(prediction[0]):.2f}')\n",
    "\n",
    "#using libraries and in built function in the library to display the outcome\n",
    "i = interact(Petal_Width, Sl=(min_sl,max_sl,0.1),\n",
    "                          Sw=(min_sw,max_sw,0.1),\n",
    "                          Pl=(min_pl,max_pl,0.1)\n",
    "            )\n",
    "display(i)\n",
    "\n",
    "#there is a resudal error in each linear regression problem.\n",
    "print ('Residual sum of squares: %.2f' % np.mean((model.predict(X)- Y) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regularization_Logistic(Regu,type):\n",
    "\n",
    "    #importing data\n",
    "    X = data[['Sepal.Length','Sepal.Width']].values #only 2 values because we are plotting 2D\n",
    "    Y = data[['Species']].values\n",
    "\n",
    "    h = .02  #smoothness of graph\n",
    "\n",
    "    if type == 'l1':\n",
    "        logreg = linear_model.LogisticRegression(C=Regu, penalty=type, solver='liblinear')#solver best for l1\n",
    "    else:\n",
    "        logreg = linear_model.LogisticRegression(C=Regu, penalty=type, solver='lbfgs')#solver best for l2\n",
    "    \n",
    "    #training data\n",
    "    logreg.fit(X, Y)\n",
    "\n",
    "    #addition and substraction of stuff to center the points of the graph\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "\n",
    "    #creating the underlying graph\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    #coloring the square based on what we think the type of flower should be there\n",
    "    Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    #plotting every color in the plot, coloring to show different flowers\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "    # Plotting data point with color \n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "\n",
    "    #Labels\n",
    "    plt.xlabel('Sepal length')\n",
    "    plt.ylabel('Sepal width')\n",
    "\n",
    "    #fitting the points\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    #cunfusion matrix\n",
    "    expected = Y\n",
    "    predicted = logreg.predict(X)\n",
    "    # summarize the fit of the model\n",
    "    print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e050bcd78574722a8627a3b8b0862bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=50.0, description='Regu', min=0.01, step=0.01), Dropdown(description='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = interact(Regularization_Logistic, Regu=(0.01,100,0.01), type=widgets.Dropdown(options=['l1', 'l2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Diagrams/Naive Bayes.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_bayes(Model_Type):\n",
    "        #importing data\n",
    "        X = data[['Sepal.Length','Sepal.Width']].values #only 2 values because we are plotting 2D\n",
    "        Y = data[['Species']].values        \n",
    "        h = .2  #smoothing of graph\n",
    "\n",
    "        #calling of different logistic regression models\n",
    "        if(Model_Type=='Gaussian'):\n",
    "            model =  GaussianNB()\n",
    "        elif (Model_Type=='Multinomial'):\n",
    "                model =  MultinomialNB()                         \n",
    "        else:\n",
    "                model =  BernoulliNB()  \n",
    "\n",
    "        #fitting the model      \n",
    "        model.fit(X, Y)\n",
    "\n",
    "        #plotting the decision boundries\n",
    "        x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "        y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "        Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "        \n",
    "        # Put the result into a color plot\n",
    "        Z = Z.reshape(xx.shape)\n",
    "        plt.figure(1, figsize=(4, 3))\n",
    "        plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "        # Plot also the training points\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "        plt.xlabel('Sepal length')\n",
    "        plt.ylabel('Sepal width')\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.xticks(())\n",
    "        plt.yticks(())\n",
    "        plt.show()\n",
    "        \n",
    "        #seeing cunfusion matrix and classification report\n",
    "        expected = Y\n",
    "        predicted = model.predict(X)\n",
    "        print(metrics.classification_report(expected, predicted))\n",
    "        print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26756dbd4f64400e81d3460a27c0c459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model Type', options=('Gaussian', 'Multinomial', 'Bernoulli'), val…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = interact(Naive_bayes, Model_Type=widgets.Dropdown(options=['Gaussian', 'Multinomial', 'Bernoulli'], description='Model Type'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Diagrams/Decision Tree.png\" width=\"50%\" style=\"background-color: white;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_Tree(Type, Depth):\n",
    "    # Select features using proper pandas syntax\n",
    "    X = data[['Sepal.Length', 'Sepal.Width']].values\n",
    "    Y = data['Species'].values\n",
    "    \n",
    "    h = .02  # step size in the mesh\n",
    "    \n",
    "    # Create and fit the Decision Tree model\n",
    "    model = DecisionTreeClassifier(criterion=Type, max_depth=Depth)\n",
    "    model.fit(X, Y)\n",
    "    \n",
    "    # Create visualization\n",
    "    x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "    y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    \n",
    "    # Plot decision boundary\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    plt.figure(1, figsize=(4, 3))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "    \n",
    "    # Plot training points\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "    plt.xlabel('Sepal Length')\n",
    "    plt.ylabel('Sepal Width')\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(f'Decision Tree (Criterion: {Type}, Max Depth: {Depth})')\n",
    "    plt.show()\n",
    "    \n",
    "    # Print classification metrics\n",
    "    predicted = model.predict(X)\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(Y, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86eab53cbd34bf19b076ea5e94b55c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Type', options=('gini', 'entropy'), value='gini'), IntSlider(value…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = interact(Decision_Tree, Type=widgets.Dropdown(options=['gini', 'entropy']), Depth=(1, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Diagrams/Random Forest.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b23c6527f84367873fd73d1aa67818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=100, description='Trees', max=1000, min=1), Output()), _dom_classes=('wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def Random_forest(n_estimators):\n",
    "    # Select features and target\n",
    "    X = data.iloc[:, :-1].values  # All columns except last\n",
    "    y = data.iloc[:, -1].values   # Last column\n",
    "    \n",
    "    # Split the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=0\n",
    "    )\n",
    "    \n",
    "    # Validate n_estimators\n",
    "    if n_estimators == 0:\n",
    "        print(\"Error: n_estimators cannot be 0\")\n",
    "        return\n",
    "    \n",
    "    # Create and train the model\n",
    "    forest = RandomForestRegressor(\n",
    "        n_estimators=n_estimators, \n",
    "        criterion='squared_error',\n",
    "        random_state=0\n",
    "    )\n",
    "    \n",
    "    # Fit the model\n",
    "    forest.fit(X_train, y_train)\n",
    "    \n",
    "    # Calculate and display scores\n",
    "    train_score = forest.score(X_train, y_train)\n",
    "    test_score = forest.score(X_test, y_test)\n",
    "    \n",
    "    print(f\"Training Score: {train_score:.4f}\")\n",
    "    print(f\"Testing Score: {test_score:.4f}\")\n",
    "    \n",
    "    return forest\n",
    "\n",
    "# Create interactive widget\n",
    "i = interact(\n",
    "    Random_forest,\n",
    "    n_estimators=widgets.IntSlider(\n",
    "        min=1,\n",
    "        max=1000,\n",
    "        step=1,\n",
    "        value=100,\n",
    "        description='Trees'\n",
    "    )\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
